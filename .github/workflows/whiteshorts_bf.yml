name: WS once-off backfill

on:
 
  workflow_dispatch:
    inputs:
      start:
        description: "Backfill start date (YYYY-MM-DD or DD/MM/YYYY)"
        required: true
        default: "2025-10-01"
      end:
        description: "Backfill end date (YYYY-MM-DD or DD/MM/YYYY)"
        required: true
        default: "2025-10-30"
      build_dashboards:
        description: "Build dashboards after backfill?"
        required: true
        default: "true"
        type: choice
        options: ["true", "false"]

concurrency:
  group: ws-backfill
  cancel-in-progress: false

jobs:
  backfill:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      actions: read
      checks: read
    env:
      PIP_DISABLE_PIP_VERSION_CHECK: "1"
      PYTHONUNBUFFERED: "1"
      WS_SLATES_DIR: data/slates
      WS_PARQUET_DIR: data/parquet
      WS_CURRENT_SEASON_PARQUET: data/current_season.parquet
      DUCKDB_PATH: data/white_shorts.duckdb
      SPORTS_DATA_BASE: https://api.sportsdata.io
      SPORTS_DATA_API_KEY: ${{ secrets.SPORTS_DATA_API_KEY }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Add src to PYTHONPATH
        run: echo "PYTHONPATH=$GITHUB_WORKSPACE/src:$PYTHONPATH" >> $GITHUB_ENV

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: pip-${{ runner.os }}-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            pip-${{ runner.os }}-

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install typer duckdb joblib scikit-learn statsmodels pandas pyarrow requests

      - name: Normalize input dates & build list
        id: dates
        env:
          INPUT_START: ${{ github.event.inputs.start }}
          INPUT_END: ${{ github.event.inputs.end }}
        run: |
          python - << 'PY'
          import os, sys
          import pandas as pd
          s_raw = (os.getenv("INPUT_START") or "").strip()
          e_raw = (os.getenv("INPUT_END") or "").strip()
          s = pd.to_datetime(s_raw, dayfirst=True, errors="coerce")
          e = pd.to_datetime(e_raw, dayfirst=True, errors="coerce")
          if pd.isna(s) or pd.isna(e) or s > e:
              raise SystemExit(f"Invalid range: start='{s_raw}' end='{e_raw}'")
          rng = pd.date_range(s.normalize(), e.normalize(), freq="D")
          with open(os.environ["GITHUB_OUTPUT"], "a") as fh:
              fh.write(f"start_norm={rng.min().date()}\n")
              fh.write(f"end_norm={rng.max().date()}\n")
              fh.write(f"days={','.join(d.date().isoformat() for d in rng)}\n")
          PY

      - name: Backfill actuals into DuckDB (day-by-day)
        env:
            DAYS: ${{ steps.dates.outputs.days }}
        run: |
            IFS=',' read -ra LIST <<< "$DAYS"
            echo "Backfilling ${#LIST[@]} day(s): ${DAYS}"
            FAIL=0
            for D in "${LIST[@]}"; do
                echo "==> Logging actuals for ${D}"
                if ! python -m white_shorts.cli.update_history "${D}"; then
                echo "::warning title=update_history failed::Date ${D} failed, continuing"
                FAIL=$((FAIL+1))
                fi
                # brief pause helps avoid rate limits
                sleep 0.4
            done
            echo "Backfill complete with ${FAIL} error day(s)."


      - name: Build dashboards (optional)
        if: ${{ github.event.inputs.build_dashboards == 'true' }}
        run: |
          python -m white_shorts.cli.dashboards build --days 60 --out data/dashboards

      - name: Upload dashboards artifacts
        if: ${{ github.event.inputs.build_dashboards == 'true' }}
        uses: actions/upload-artifact@v4
        with:
          name: dashboards-backfill-${{ steps.dates.outputs.start_norm }}_to_${{ steps.dates.outputs.end_norm }}
          path: |
            data/dashboards/*.csv
            data/dashboards/*.html
          retention-days: 14

      - name: Ensure models are ignored
        run: |
          grep -q '^models/$' .gitignore || echo 'models/' >> .gitignore

      - name: Commit dashboards (if built)
        if: ${{ github.event.inputs.build_dashboards == 'true' }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add -A data/dashboards/*.csv || true
          git add -A data/dashboards/*.html || true
          if git diff --cached --quiet; then
            echo "No dashboard changes to commit."
          else
            git commit -m "Backfill dashboards for ${{ steps.dates.outputs.start_norm }} → ${{ steps.dates.outputs.end_norm }} [skip ci]"
            git push origin HEAD:${{ github.ref_name }}
          fi

      - name: Commit DuckDB state
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          if [ -f "${{ env.DUCKDB_PATH }}" ]; then
            git add -f "${{ env.DUCKDB_PATH }}"
            if git diff --cached --quiet; then
              echo "No DuckDB changes to commit."
            else
              git commit -m "Backfill DuckDB for ${{ steps.dates.outputs.start_norm }} → ${{ steps.dates.outputs.end_norm }} [skip ci]"
              git push origin HEAD:${{ github.ref_name }}
            fi
          else
            echo "DuckDB not found at ${{ env.DUCKDB_PATH }}; skipping commit."
          fi
